# 考公 RAG 系统设计方案

基于对 `fenbi-crawler` 项目中爬取的试卷数据（JSON格式）的分析，针对考公（公务员）考试的 RAG（检索增强生成）系统设计建议如下。核心目标是解决数据的**颗粒度**和**上下文完整性**问题。

## 1. 数据结构特点分析

通过对下载的 JSON 试卷文件（如 `downloads\上海\...\*.json`）的抽样分析，数据主要分为两类结构：

*   **常规单题 (`type: "regular"`)**
    *   结构：独立的题目对象。
    *   包含字段：
        *   `stem` (题干)
        *   `options` (选项列表)
        *   `analysis` (解析)
        *   `keypoints` (考点标签)
        *   `correct_answer` (正确答案)

*   **材料题 (`type: "material"`)**
    *   结构：嵌套结构，包含一个共享的背景材料和一组子问题。
    *   包含字段：
        *   `material.content` (长篇背景材料)
        *   `questions` (子问题列表，每个子问题结构同常规单题)
    *   **难点**：子问题的题干（如“根据本文内容...”）通常脱离材料无法独立理解。

## 2. 文档加载与处理建议 (ETL策略)

**核心原则**：不要直接将整个 JSON 文件视为一个文档，也不要使用简单的字符长度切分（Character Split）。应以**“一道完整的题目”**作为检索的最小原子单位。

### A. 数据平铺 (Flattening)
建议编写脚本遍历所有 JSON，将数据“打平”，转化为统一的列表格式。

*   **对于常规单题**：
    直接提取为一个独立的文档对象。
*   **对于材料题（关键策略）**：
    采用**“冗余包含”**策略。将公共的 `material.content` 复制并拼接到该大题下的**每一个**子题目中。
    *   *理由*：如果用户搜索“关于啤酒与人类文明关系的题目”，我们需要检索到具体的那个子题目。如果题目和材料分离，检索匹配度会大幅下降。尽管这会增加索引体积，但能显著提高检索准确率。

### B. 元数据提取 (Metadata Extraction)
RAG 不仅仅靠文本相似度，**结构化过滤 (Filtering)** 至关重要。需从文件路径和 JSON 字段提取以下元数据，附加到每个 Chunk 上：

| 元数据字段 | 来源描述 | 示例 | 作用 |
| :--- | :--- | :--- | :--- |
| `province` | `filter` 字段或文件路径 | "上海" |实现“只看上海真题”的过滤 |
| `year` | 文件路径 | "2023" | 实现“只看近三年真题”的过滤 |
| `category` | `keypoints` 数组 | ["实词填空", "词的辨析"] | 实现按知识点定向检索，如“帮我找几道实词填空的题” |
| `doc_type` | `type` 字段 | "regular" / "material" | 区分题型结构 |
| `source` | `source` 字段 | "2023年上海市..." | 引用溯源 |

## 3. 文本分块与格式化策略 (Chunking Strategy)

由于数据本身已经是语义完整的（题目+解析），我们**不需要**使用传统的 `RecursiveCharacterTextSplitter` 进行机械切分。我们应该使用**结构化重组**的方式来生成用于 Embedding 的文本。

建议为每个 Document 构建如下格式的 `page_content` 字符串进行 Embedding：

### 方案：语义完整块 (Context-Aware Chunk)

**文本构造模板：**

```text
【考点】：{keypoints 逗号分隔}
【背景材料】：
{如果是材料题，在此处插入 material.content}
【题目】：
{stem}
【选项】：
A. {option A}
B. {option B}
...
【答案解析】：
正确答案：{correct_answer}
解析：{analysis}
```

### 实施细节建议：

1.  **纯文本化选项**：
    将 `options` 数组转换为字符串（如 "A. 选项内容\n B. 选项内容..."），使模型能理解选项内容。

2.  **包含解析 (Analysis)**：
    **强烈建议将 `analysis` 包含在 Embedding 内容中**。
    *   *理由*：用户的提问往往是概念性的（例如“如何区分‘截止’和‘截至’？”）。题目原文中可能没有这两个词的辨析，但 `analysis` 中会有详细解释。索引解析可以让系统具备“按原理解题”的能力，而不仅仅是匹配题目字面。

3.  **Token 限制处理**：
    *   普通题通常不会超长。
    *   材料题（尤其是申论或长篇言语理解）的材料+解析可能超过 Embedding 模型的 Token 限制（如 8192 或 512）。
    *   *对策*：如果使用支持长文本的模型（如 OpenAI text-embedding-3-small/large 或 bge-m3），通常可以直接容纳。如果必须截断，优先保留**题目、选项和解析**，对**背景材料**进行从后往前的截断（因为题目通常针对材料的特定段落，但保留开头和结尾通常较稳妥，或者对超长材料单独做摘要）。

## 4. 推荐的 Pipeline 流程

1.  **Extract (提取)**:
    读取项目目录下的所有 `*.json` 文件。
2.  **Transform (转换)**:
    *   遍历 `items` 列表。
    *   如果是 `regular`: 构造 `Text = "题干... 选项... 解析..."`, `Metadata = {Year, Province, Keypoints...}`。
    *   如果是 `material`: 遍历其 `questions`。对每个子题，构造 `Text = "材料内容... 题干... 选项... 解析..."`, `Metadata = {Year, Province, Keypoints...}`。
3.  **Embed & Load (向量化与存储)**:
    将上述构建好的 Document 列表存入向量数据库（Chroma / Faiss / Milvus / Elasticsearch 等）。

这种策略将把非结构化的 RAG 问题转化为了结构化数据的精准查找问题，效果会远好于盲目的文本切片。
